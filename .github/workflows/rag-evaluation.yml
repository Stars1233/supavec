name: RAG Evaluation

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'packages/api/**'
      - 'eval/**'
      - '.github/workflows/rag-evaluation.yml'

jobs:
  rag-evaluation:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('eval/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        cd eval
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run RAG evaluation
      env:
        SUPAVEC_BASE_URL: ${{ secrets.SUPAVEC_BASE_URL }}
        SUPAVEC_API_KEY: ${{ secrets.SUPAVEC_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        FILE_ID: ${{ secrets.FILE_ID }}
      run: |
        cd eval
        python evaluate_rag_with_ragas.py > evaluation_results.txt 2>&1
        
    - name: Upload evaluation results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: rag-evaluation-results-${{ github.event.number }}
        path: eval/evaluation_results.txt
        retention-days: 30
        
    - name: Check evaluation results
      run: |
        cd eval
        if grep -q "Error during RAGAS evaluation" evaluation_results.txt; then
          echo "‚ùå RAG evaluation failed"
          cat evaluation_results.txt
          exit 1
        elif grep -q "RAG EVALUATION RESULTS" evaluation_results.txt; then
          echo "‚úÖ RAG evaluation completed successfully"
          echo "## RAG Evaluation Results" >> $GITHUB_STEP_SUMMARY
          echo "```" >> $GITHUB_STEP_SUMMARY
          grep -A 20 "RAG EVALUATION RESULTS" evaluation_results.txt >> $GITHUB_STEP_SUMMARY
          echo "```" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ö†Ô∏è RAG evaluation completed with warnings"
          cat evaluation_results.txt
        fi
        
    - name: Comment PR with results
      uses: actions/github-script@v7
      if: always()
      with:
        script: |
          const fs = require('fs').promises;
          const path = 'eval/evaluation_results.txt';
          
          try {
            const results = await fs.readFile(path, 'utf8');
            const hasResults = results.includes('RAG EVALUATION RESULTS');
            const hasError = results.includes('Error during RAGAS evaluation');
            
            let comment = '## üß™ RAG Evaluation Results\n\n';
            
            if (hasError) {
              comment += '‚ùå **Evaluation Failed**\n\n';
              comment += '```\n' + results.split('\n').slice(-20).join('\n') + '\n```';
            } else if (hasResults) {
              comment += '‚úÖ **Evaluation Completed Successfully**\n\n';
              const resultsSection = results.split('RAG EVALUATION RESULTS')[1];
              if (resultsSection) {
                comment += '```\n' + resultsSection.split('='.repeat(50))[0].trim() + '\n```';
              }
            } else {
              comment += '‚ö†Ô∏è **Evaluation Completed with Warnings**\n\n';
              comment += '```\n' + results.split('\n').slice(-10).join('\n') + '\n```';
            }
            
            comment += '\nüìä [View full results in artifacts](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})';
            
            // Update or create comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const existingComment = comments.find(comment => 
              comment.user.login === 'github-actions[bot]' && 
              comment.body.includes('üß™ RAG Evaluation Results')
            );
            
            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
          } catch (error) {
            console.error('Error reading results file:', error);
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: '## üß™ RAG Evaluation Results\n\n‚ùå **Failed to read evaluation results**\n\nCheck the [action logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details.'
            });
          } 